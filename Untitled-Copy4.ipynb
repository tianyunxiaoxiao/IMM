{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5dd180c-410a-4c2e-b2cb-c4b4b3065e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =============================\n",
    "# 1. Êï∞ÊçÆÂä†ËΩΩ\n",
    "# =============================\n",
    "def load_data(file_path):\n",
    "    \"\"\"Âä†ËΩΩÂéüÂßãÊï∞ÊçÆÂπ∂ËΩ¨Êç¢Êï∞ÊçÆÁ±ªÂûã\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # ËΩ¨Êç¢Êó∂Èó¥Ê†ºÂºèÂπ∂ËÆæ‰∏∫Á¥¢Âºï\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    \n",
    "    # Êï∞ÊçÆÁ±ªÂûãËΩ¨Êç¢\n",
    "    numeric_cols = [\n",
    "        'price', 'volume', 'turnover', 'ask_order', 'bid_order', \n",
    "        'num', 'count', 'exchtime', 'localtime'\n",
    "    ]\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    return df\n",
    "\n",
    "# =============================\n",
    "# 2. Êï∞ÊçÆÊ∏ÖÊ¥ó\n",
    "# =============================\n",
    "def process_data(df):\n",
    "    \"\"\"Êï∞ÊçÆÊ∏ÖÊ¥ó‰∏éÈ¢ÑÂ§ÑÁêÜ\"\"\"\n",
    "    # ÂâçÂêëÂ°´ÂÖÖ & Áî® 0 Â°´ÂÖÖ\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    # ÂéªÈáç\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    # Á≠õÊéâ‰∏çÂêàÊ≥ïÁöÑ‰ª∑Ê†º/Êàê‰∫§Èáè\n",
    "    df = df[(df['price'] >= 0) & (df['volume'] >= 0)]\n",
    "\n",
    "    # ÊûÑÈÄ†‰∏Ä‰∏™ÁÆÄÂçïÁöÑ price_tick\n",
    "    df['price_tick'] = df['price'] / df['price'].max()\n",
    "\n",
    "    # ËΩ¨Êç¢ time ÂàóÔºåÂ¶ÇÊûúÊ≤°ÊúâËøôÂàóÂèØÊ≥®ÈáäÊéâ\n",
    "    if 'time' in df.columns:\n",
    "        df['time'] = pd.to_datetime(df['time'], format='%H%M%S%f', errors='coerce')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# =============================\n",
    "# 3. ÁâπÂæÅÂ∑•Á®ã\n",
    "# =============================\n",
    "def generate_features(df):\n",
    "    \"\"\"\n",
    "    ÁâπÂæÅÂ∑•Á®ãÔºöÊûÑÈÄ†Â∏ÇÂú∫ÁâπÂæÅ„ÄÅËÆ¢ÂçïÁâπÂæÅÂíåÂÆèËßÇÁâπÂæÅ\n",
    "    \"\"\"\n",
    "    df['mid_price'] = (df['price'].shift(-1) + df['price']) / 2\n",
    "    df['price_change'] = df['price'].shift(-20) - df['price']\n",
    "    df['volume_change'] = df['volume'].diff()\n",
    "\n",
    "    # ËøáÂéª N tick ÁöÑÂùáÂÄºÂèòÂåñ\n",
    "    df['rolling_mean_20'] = df['price'].rolling(window=20).mean()\n",
    "    df['rolling_mean_120'] = df['price'].rolling(window=120).mean()\n",
    "\n",
    "    df['ask_bid_spread'] = df['ask_order'] - df['bid_order']\n",
    "    df['order_flow_imbalance'] = (df['ask_order'] - df['bid_order']) / (df['ask_order'] + df['bid_order'] + 1e-6)\n",
    "\n",
    "    df['turnover_change'] = df['turnover'].diff()\n",
    "    df['volume_ratio_20'] = df['volume'] / (df['volume'].rolling(20).mean() + 1e-6)\n",
    "    df['turnover_ratio_20'] = df['turnover'] / (df['turnover'].rolling(20).mean() + 1e-6)\n",
    "\n",
    "    df['volatility_20'] = df['price'].rolling(20).std()\n",
    "\n",
    "    df['future_return_20'] = df['price'].shift(-20) / df['price'] - 1\n",
    "    df['future_return_120'] = df['price'].shift(-120) / df['price'] - 1\n",
    "\n",
    "    df['flag_encoded'] = pd.factorize(df['flag'])[0]\n",
    "\n",
    "    # ========== üîç Â§ÑÁêÜÊó†Á©∑Â§ß„ÄÅËøáÂ§ßÊï∞ÂÄº„ÄÅNaN ==========\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)  # Â∞Ü inf ÊõøÊç¢‰∏∫ NaN\n",
    "    df.fillna(0, inplace=True)                          # Â∞Ü NaN ÊõøÊç¢‰∏∫ 0\n",
    "\n",
    "    return df\n",
    "\n",
    "# =============================\n",
    "# 4. Êï∞ÊçÆ‰øùÂ≠ò\n",
    "# =============================\n",
    "def save_data(df, file_path):\n",
    "    \"\"\"‰øùÂ≠òÂ§ÑÁêÜÂêéÁöÑÊï∞ÊçÆ\"\"\"\n",
    "    df.to_csv(file_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91d97a83-026b-44d9-91d0-14b14e1a4ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =============================\n",
    "# 1. ËÆ°ÁÆó PnL (Episodic Profit and Loss)\n",
    "# =============================\n",
    "def calculate_pnl(df):\n",
    "    df['side'] = np.where(df['order_type'] == 1, 1, -1)\n",
    "    df['pnl'] = df['side'] * (df['price'].shift(-1) - df['price']) * df['volume']\n",
    "    return df['pnl'].sum()\n",
    "\n",
    "# =============================\n",
    "# 2. ËÆ°ÁÆó MAP (Mean Absolute Position)\n",
    "# =============================\n",
    "def calculate_map(df):\n",
    "    if 'inventory' not in df.columns:\n",
    "        df['inventory'] = df['volume'].cumsum()\n",
    "    return df['inventory'].abs().mean()\n",
    "\n",
    "# =============================\n",
    "# 3. ËÆ°ÁÆó Adverse Selection Ratio\n",
    "# =============================\n",
    "def calculate_adverse_selection_ratio(df):\n",
    "    adverse_conditions = (\n",
    "        ((df['order_type'] == 1) & (df['price'] > df['mid_price'])) |\n",
    "        ((df['order_type'] == -1) & (df['price'] < df['mid_price']))\n",
    "    )\n",
    "    adverse_orders = df[adverse_conditions].shape[0]\n",
    "    total_orders = df.shape[0]\n",
    "    return adverse_orders / total_orders if total_orders > 0 else 0\n",
    "\n",
    "# =============================\n",
    "# 4. ËÆ°ÁÆó RPT (Return Per Trade)\n",
    "# =============================\n",
    "def calculate_rpt(df):\n",
    "    total_trades = df.shape[0]\n",
    "    total_pnl = calculate_pnl(df)\n",
    "    return total_pnl / total_trades if total_trades > 0 else 0\n",
    "\n",
    "# =============================\n",
    "# 5. ËÆ°ÁÆó PnL-to-MAP Ratio\n",
    "# =============================\n",
    "def calculate_pnl_map_ratio(df):\n",
    "    pnl = calculate_pnl(df)\n",
    "    map_value = calculate_map(df)\n",
    "    return pnl / map_value if map_value != 0 else 0\n",
    "\n",
    "# =============================\n",
    "# 6. ËØÑ‰º∞Á≠ñÁï•‰∏ªÂáΩÊï∞\n",
    "# =============================\n",
    "def evaluate_strategy(df):\n",
    "    metrics = {\n",
    "        \"Total PnL\": calculate_pnl(df),\n",
    "        \"Mean Absolute Position (MAP)\": calculate_map(df),\n",
    "        \"Adverse Selection Ratio\": calculate_adverse_selection_ratio(df),\n",
    "        \"Return Per Trade (RPT)\": calculate_rpt(df),\n",
    "        \"PnL-to-MAP Ratio\": calculate_pnl_map_ratio(df)\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "689dfe36-feea-4a01-8c88-0dfdc1d23c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class MarketReplaySimulator:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.executed_orders = []\n",
    "\n",
    "    def market_replay(self):\n",
    "        \"\"\"\n",
    "        Â∏ÇÂú∫ÂõûÊîæÊ®°ÊãüÂô®ÔºöÊâßË°åËÆ¢ÂçïÂåπÈÖç‰∏éÊàê‰∫§\n",
    "        \"\"\"\n",
    "        self.df['inventory'] = 0  # ÂàùÂßãÂåñÂ∫ìÂ≠ò\n",
    "\n",
    "        for index, row in self.df.iterrows():\n",
    "            mid_price = row['mid_price']\n",
    "\n",
    "            # Ê®°ÊãüÂ§ö‰ª∑‰ΩçËÆ¢ÂçïÁ∞ø\n",
    "            ask_price = mid_price + 0.01  # Ê®°ÊãüÂçñÂçï‰ª∑\n",
    "            bid_price = mid_price - 0.01  # Ê®°Êãü‰π∞Âçï‰ª∑\n",
    "\n",
    "            # Ê®°ÊãüÊàê‰∫§ (‰ª∑Ê†ºÊ≥¢Âä®Ëß¶ÂèëÊàê‰∫§)\n",
    "            executed_order = None\n",
    "            if row['price'] >= ask_price:  # ÂçñÂçïÊàê‰∫§\n",
    "                executed_order = {\n",
    "                    'price': ask_price,\n",
    "                    'volume': row['volume'],\n",
    "                    'side': 'sell',\n",
    "                    'inventory': self.df.loc[index, 'inventory'] - row['volume']  # ÂáèÊåÅ‰ªì\n",
    "                }\n",
    "            elif row['price'] <= bid_price:  # ‰π∞ÂçïÊàê‰∫§\n",
    "                executed_order = {\n",
    "                    'price': bid_price,\n",
    "                    'volume': row['volume'],\n",
    "                    'side': 'buy',\n",
    "                    'inventory': self.df.loc[index, 'inventory'] + row['volume']  # Â¢ûÊåÅ‰ªì\n",
    "                }\n",
    "\n",
    "            if executed_order:\n",
    "                self.executed_orders.append(executed_order)\n",
    "                self.df.loc[index, 'inventory'] = executed_order['inventory']\n",
    "\n",
    "        return pd.DataFrame(self.executed_orders)\n",
    "\n",
    "    def save_executed_orders(self, output_path):\n",
    "        \"\"\"\n",
    "        ‰øùÂ≠òÊàê‰∫§ËÆ¢ÂçïÊï∞ÊçÆ\n",
    "        \"\"\"\n",
    "        executed_orders_df = pd.DataFrame(self.executed_orders)\n",
    "        executed_orders_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec69cecc-0a41-48bb-be6f-d293c7408182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "# =============================\n",
    "# 1. Actor ÁΩëÁªú (Á≠ñÁï•ÁΩëÁªú)\n",
    "# =============================\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(state_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, action_dim),\n",
    "            nn.Tanh()  # Tanh Á°Æ‰øùÂä®‰ΩúÂÄºÂú® (-1, 1) ‰πãÈó¥\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# =============================\n",
    "# 2. Critic ÁΩëÁªú (‰ª∑ÂÄºÁΩëÁªú)\n",
    "# =============================\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(state_dim + action_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], dim=1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# =============================\n",
    "# 3. TD3 Agent\n",
    "# =============================\n",
    "class TD3_Agent:\n",
    "    def __init__(self, state_dim, action_dim, lr=0.001, gamma=0.99, tau=0.005):\n",
    "        self.actor = Actor(state_dim, action_dim)\n",
    "        self.actor_target = Actor(state_dim, action_dim)\n",
    "        self.actor_target.load_state_dict(self.actor.state_dict())  # ÂàùÂßãÊó∂‰∏§ËÄÖÂèÇÊï∞Áõ∏Âêå\n",
    "\n",
    "        self.critic_1 = Critic(state_dim, action_dim)\n",
    "        self.critic_1_target = Critic(state_dim, action_dim)\n",
    "        self.critic_1_target.load_state_dict(self.critic_1.state_dict())\n",
    "\n",
    "        self.critic_2 = Critic(state_dim, action_dim)\n",
    "        self.critic_2_target = Critic(state_dim, action_dim)\n",
    "        self.critic_2_target.load_state_dict(self.critic_2.state_dict())\n",
    "\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=lr)\n",
    "        self.critic_1_optimizer = optim.Adam(self.critic_1.parameters(), lr=lr)\n",
    "        self.critic_2_optimizer = optim.Adam(self.critic_2.parameters(), lr=lr)\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "\n",
    "        self.replay_buffer = deque(maxlen=100000)  # ÁªèÈ™åÂõûÊîæ\n",
    "\n",
    "    # =============================\n",
    "    # 4. ÁªèÈ™åÂõûÊîæ (Replay Buffer)\n",
    "    # =============================\n",
    "    def store_experience(self, state, action, reward, next_state, done):\n",
    "        self.replay_buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample_experience(self, batch_size):\n",
    "        return random.sample(self.replay_buffer, batch_size)\n",
    "\n",
    "    # =============================\n",
    "    # 5. ËÆ≠ÁªÉÂáΩÊï∞\n",
    "    # =============================\n",
    "    def train(self, batch_size=64):\n",
    "        if len(self.replay_buffer) < batch_size:\n",
    "            return  # Êï∞ÊçÆ‰∏çË∂≥Êó∂‰∏çËÆ≠ÁªÉ\n",
    "\n",
    "        batch = self.sample_experience(batch_size)\n",
    "        state, action, reward, next_state, done = zip(*batch)\n",
    "\n",
    "        state = torch.FloatTensor(state)\n",
    "        action = torch.FloatTensor(action)\n",
    "        reward = torch.FloatTensor(reward).unsqueeze(1)\n",
    "        next_state = torch.FloatTensor(next_state)\n",
    "        done = torch.FloatTensor(done).unsqueeze(1)\n",
    "\n",
    "        # ÁõÆÊ†áÁ≠ñÁï•ÁΩëÁªúÁöÑÂä®‰Ωú + ÁõÆÊ†áÂô™Â£∞ (TD3 ÁâπÊúâÊú∫Âà∂)\n",
    "        noise = torch.randn_like(action) * 0.2\n",
    "        noise = noise.clamp(-0.5, 0.5)\n",
    "        next_action = self.actor_target(next_state) + noise\n",
    "\n",
    "        # ÁõÆÊ†á Q ÂÄº (Âèñ‰∏§‰∏™ Critic ÁöÑÊúÄÂ∞èÂÄº)\n",
    "        target_q1 = self.critic_1_target(next_state, next_action)\n",
    "        target_q2 = self.critic_2_target(next_state, next_action)\n",
    "        target_q = reward + self.gamma * (1 - done) * torch.min(target_q1, target_q2)\n",
    "\n",
    "        # Critic ÁΩëÁªú‰ºòÂåñ\n",
    "        current_q1 = self.critic_1(state, action)\n",
    "        current_q2 = self.critic_2(state, action)\n",
    "\n",
    "        critic_1_loss = F.mse_loss(current_q1, target_q.detach())\n",
    "        critic_2_loss = F.mse_loss(current_q2, target_q.detach())\n",
    "\n",
    "        self.critic_1_optimizer.zero_grad()\n",
    "        critic_1_loss.backward()\n",
    "        self.critic_1_optimizer.step()\n",
    "\n",
    "        self.critic_2_optimizer.zero_grad()\n",
    "        critic_2_loss.backward()\n",
    "        self.critic_2_optimizer.step()\n",
    "\n",
    "        # ÊØè 2 Ê¨° critic Êõ¥Êñ∞ÂêéÊâçÊõ¥Êñ∞ actor\n",
    "        if np.random.randint(0, 2) == 0:\n",
    "            actor_loss = -self.critic_1(state, self.actor(state)).mean()\n",
    "            self.actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "\n",
    "            # Êõ¥Êñ∞ÁõÆÊ†áÁΩëÁªú (Soft Update)\n",
    "            for target_param, param in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
    "                target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "            for target_param, param in zip(self.critic_1_target.parameters(), self.critic_1.parameters()):\n",
    "                target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "            for target_param, param in zip(self.critic_2_target.parameters(), self.critic_2.parameters()):\n",
    "                target_param.data.copy_(self.tau * param.data + (1 - self.tau) * target_param.data)\n",
    "\n",
    "    # =============================\n",
    "    # 6. ‰øùÂ≠ò & Âä†ËΩΩÊ®°Âûã\n",
    "    # =============================\n",
    "    def save_model(self, path):\n",
    "        torch.save(self.actor.state_dict(), path)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.actor.load_state_dict(torch.load(path))\n",
    "        self.actor_target.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5ffd453-a4ac-4a6b-af01-4ebdd99bca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import joblib  # Ê®°Âûã‰øùÂ≠ò\n",
    "import numpy as np\n",
    "\n",
    "# =============================\n",
    "# 1. LightGBM Ê®°Âûã (Ê¢ØÂ∫¶ÊèêÂçáÊ†ë)\n",
    "# =============================\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "def train_lightgbm(df, model_path):\n",
    "    \"\"\"\n",
    "    ËÆ≠ÁªÉ LightGBM Ê®°Âûã‰ª•È¢ÑÊµãÁü≠Êúü/ÈïøÊúü‰ª∑Ê†ºË∂ãÂäø‰ø°Âè∑\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        'mid_price', 'volume_change', 'rolling_mean_20',\n",
    "        'rolling_mean_120', 'ask_bid_spread', 'order_flow_imbalance'\n",
    "    ]\n",
    "    target = 'future_return_20'\n",
    "\n",
    "    # Êï∞ÊçÆÂàÜÂâ≤\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.3, random_state=42)\n",
    "\n",
    "    # ========== üîç Êï∞ÊçÆÊ£ÄÊü•Âπ∂Â§ÑÁêÜ NaN / Inf / ËøáÂ§ßÊï∞ÂÄº ==========\n",
    "    def clean_data(data):\n",
    "        data.replace([np.inf, -np.inf], np.nan, inplace=True)  # Â∞Ü inf ÊõøÊç¢‰∏∫ NaN\n",
    "        data.fillna(0, inplace=True)                            # Â∞Ü NaN ÊõøÊç¢‰∏∫ 0\n",
    "        return data\n",
    "\n",
    "    X_train, X_test = clean_data(X_train), clean_data(X_test)\n",
    "    y_train, y_test = clean_data(y_train), clean_data(y_test)\n",
    "\n",
    "    # Ê£ÄÊü•ÊòØÂê¶‰ªçÂ≠òÂú®ÂºÇÂ∏∏ÂÄº\n",
    "    if np.any(np.isinf(X_train)) or np.any(np.isinf(y_train)):\n",
    "        raise ValueError(\"‚ùó X_train Êàñ y_train ‰ªçÂåÖÂê´Êó†Á©∑Â§ßÊàñÂºÇÂ∏∏ÂÄº\")\n",
    "    if np.any(np.isinf(X_test)) or np.any(np.isinf(y_test)):\n",
    "        raise ValueError(\"‚ùó X_test Êàñ y_test ‰ªçÂåÖÂê´Êó†Á©∑Â§ßÊàñÂºÇÂ∏∏ÂÄº\")\n",
    "\n",
    "    # Ê®°ÂûãËÆ≠ÁªÉ\n",
    "    model = lgb.LGBMRegressor(n_estimators=200, learning_rate=0.05)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Ê®°ÂûãËØÑ‰º∞\n",
    "    preds = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    print(f'‚úÖ LightGBM ËÆ≠ÁªÉÂÆåÊàê - Mean Squared Error: {mse:.4f}')\n",
    "\n",
    "    # ‰øùÂ≠òÊ®°Âûã\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f'‚úÖ LightGBM Ê®°ÂûãÂ∑≤‰øùÂ≠òËá≥: {model_path}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# =============================\n",
    "# 2. LSTM Ê®°Âûã (Êó∂Â∫èÊ∑±Â∫¶ÁΩëÁªú)\n",
    "# =============================\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        return self.fc(lstm_out[:, -1, :])  # ÂèñÊúÄÂêé‰∏Ä‰∏™Êó∂Èó¥Ê≠•ÁöÑËæìÂá∫\n",
    "\n",
    "def train_lstm(df, model_path, epochs=20, batch_size=64):\n",
    "    \"\"\"\n",
    "    ËÆ≠ÁªÉ LSTM Ê®°ÂûãÁî®‰∫éË∂ãÂäøÈ¢ÑÊµã\n",
    "    \"\"\"\n",
    "    features = ['mid_price', 'volume_change', 'rolling_mean_20', 'rolling_mean_120']\n",
    "    target = 'future_return_20'\n",
    "\n",
    "    X = torch.tensor(df[features].values, dtype=torch.float32).unsqueeze(1)  # Ê∑ªÂä†Êó∂Èó¥Áª¥Â∫¶\n",
    "    y = torch.tensor(df[target].values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    model = LSTMModel(input_dim=X.shape[2], hidden_dim=32, output_dim=1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X)\n",
    "        loss = loss_fn(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f'Epoch {epoch + 1}/{epochs} - Loss: {loss.item():.4f}')\n",
    "\n",
    "    # ‰øùÂ≠òÊ®°Âûã\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f'‚úÖ LSTM Ê®°ÂûãÂ∑≤‰øùÂ≠òËá≥: {model_path}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# =============================\n",
    "# 3. Ê®°ÂûãÂä†ËΩΩ\n",
    "# =============================\n",
    "def load_lightgbm(model_path):\n",
    "    \"\"\"Âä†ËΩΩ LightGBM Ê®°Âûã\"\"\"\n",
    "    return joblib.load(model_path)\n",
    "\n",
    "def load_lstm(model_path, input_dim):\n",
    "    \"\"\"Âä†ËΩΩ LSTM Ê®°Âûã\"\"\"\n",
    "    model = LSTMModel(input_dim=input_dim, hidden_dim=32, output_dim=1)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model\n",
    "\n",
    "# =============================\n",
    "# 4. È¢ÑÊµã‰ø°Âè∑\n",
    "# =============================\n",
    "def predict_signal(df, model, model_type='lightgbm'):\n",
    "    \"\"\"\n",
    "    ‰ΩøÁî®ËÆ≠ÁªÉÂ•ΩÁöÑÊ®°ÂûãËøõË°å‰ø°Âè∑È¢ÑÊµã\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        'mid_price', 'volume_change', 'rolling_mean_20',\n",
    "        'rolling_mean_120', 'ask_bid_spread', 'order_flow_imbalance'\n",
    "    ]\n",
    "\n",
    "    X = df[features]\n",
    "\n",
    "    if model_type == 'lightgbm':\n",
    "        return model.predict(X)\n",
    "\n",
    "    elif model_type == 'lstm':\n",
    "        X = torch.tensor(X.values, dtype=torch.float32).unsqueeze(1)  # Ê∑ªÂä†Êó∂Èó¥Áª¥Â∫¶\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            return model(X).numpy().flatten()\n",
    "\n",
    "# =============================\n",
    "# 5. ÁâπÂæÅÁ≠õÈÄâ\n",
    "# =============================\n",
    "def feature_selection(df):\n",
    "    \"\"\"\n",
    "    Âä®ÊÄÅÁ≠õÈÄâÊúÄÁõ∏ÂÖ≥ÁöÑÁâπÂæÅ\n",
    "    \"\"\"\n",
    "    correlation = df.corr()['future_return_20'].abs().sort_values(ascending=False)\n",
    "    top_features = correlation.index[:6].tolist()\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b041e6d-48f2-4b76-bdfa-df2dc8d04c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessing import load_data, process_data, generate_features\n",
    "from src.signal_model import train_lightgbm, train_lstm, load_lightgbm, load_lstm\n",
    "from src.market_replay import MarketReplaySimulator\n",
    "from src.rl_model import TD3_Agent\n",
    "from src.evaluation import evaluate_strategy\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# =============================\n",
    "# ÈÖçÁΩÆË∑ØÂæÑ\n",
    "# =============================\n",
    "RAW_DATA_PATH = \"/nas197/uhome/zhangrui/merged_transaction_20241113.csv\"\n",
    "PROCESSED_DATA_PATH = \"./data/processed/processed_data.csv\"\n",
    "FEATURES_PATH = \"./data/features/executed_orders.csv\"\n",
    "LGB_MODEL_PATH = \"./models/signal_model.pkl\"\n",
    "LSTM_MODEL_PATH = \"./models/lstm_model.pth\"\n",
    "RL_MODEL_PATH = \"./models/rl_model.pth\"\n",
    "\n",
    "# === Êñ∞Â¢ûÔºöËØÑ‰ª∑ÊåáÊ†á‰∏éÂèØËßÜÂåñÊñá‰ª∂ÁöÑ‰øùÂ≠òË∑ØÂæÑ ===\n",
    "EVAL_METRICS_PATH = \"./results/evaluation_metrics.txt\"\n",
    "EQUITY_CURVE_PATH = \"./results/equity_curve.png\"\n",
    "\n",
    "# =============================\n",
    "# 1. Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÊµÅÁ®ã\n",
    "# =============================\n",
    "def preprocess_data():\n",
    "    print(\"üîÑ Âä†ËΩΩÂéüÂßãÊï∞ÊçÆ...\")\n",
    "    data = load_data(RAW_DATA_PATH)\n",
    "    print(f\"‚úÖ Êï∞ÊçÆÂä†ËΩΩÂÆåÊàê, Êï∞ÊçÆÁª¥Â∫¶: {data.shape}\")\n",
    "\n",
    "    print(\"üîÑ Êï∞ÊçÆÊ∏ÖÊ¥óÂíåÈ¢ÑÂ§ÑÁêÜ...\")\n",
    "    processed_data = process_data(data)\n",
    "    feature_data = generate_features(processed_data)\n",
    "    \n",
    "    print(\"üíæ Ê≠£Âú®‰øùÂ≠òÂ§ÑÁêÜÂêéÁöÑÊï∞ÊçÆ...\")\n",
    "    feature_data.to_csv(PROCESSED_DATA_PATH, index=False)\n",
    "    print(f\"‚úÖ Êï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥: {PROCESSED_DATA_PATH}\")\n",
    "    \n",
    "    return feature_data\n",
    "\n",
    "# =============================\n",
    "# 2. ËÆ≠ÁªÉ‰ø°Âè∑Ê®°Âûã\n",
    "# =============================\n",
    "def train_signal_models(feature_data):\n",
    "    print(\"üöÄ ÂºÄÂßãËÆ≠ÁªÉ LightGBM ‰ø°Âè∑Ê®°Âûã...\")\n",
    "    train_lightgbm(feature_data, LGB_MODEL_PATH)\n",
    "\n",
    "    print(\"üöÄ ÂºÄÂßãËÆ≠ÁªÉ LSTM ‰ø°Âè∑Ê®°Âûã...\")\n",
    "    train_lstm(feature_data, LSTM_MODEL_PATH)\n",
    "\n",
    "# =============================\n",
    "# 3. Â∏ÇÂú∫ÂõûÊîæÊ®°ÊãüÂô®\n",
    "# =============================\n",
    "def run_market_replay(feature_data):\n",
    "    print(\"üöÄ ÂêØÂä®Â∏ÇÂú∫ÂõûÊîæÊ®°ÊãüÂô®...\")\n",
    "    simulator = MarketReplaySimulator(feature_data)\n",
    "    executed_orders = simulator.market_replay()\n",
    "\n",
    "    print(\"üíæ Ê≠£Âú®‰øùÂ≠òÊàê‰∫§ËÆ¢ÂçïÊï∞ÊçÆ...\")\n",
    "    simulator.save_executed_orders(FEATURES_PATH)\n",
    "    print(f\"‚úÖ Êàê‰∫§ËÆ¢ÂçïÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥: {FEATURES_PATH}\")\n",
    "\n",
    "# =============================\n",
    "# 4. Âº∫ÂåñÂ≠¶‰π†Ê®°ÂûãËÆ≠ÁªÉ\n",
    "# =============================\n",
    "def train_rl_model(feature_data):\n",
    "    print(\"üöÄ ÂºÄÂßãËÆ≠ÁªÉ TD3 Âº∫ÂåñÂ≠¶‰π†Ê®°Âûã...\")\n",
    "\n",
    "    simulator = MarketReplaySimulator(feature_data)\n",
    "    state_dim = simulator.state_dim\n",
    "    action_dim = simulator.action_dim\n",
    "\n",
    "    rl_agent = TD3_Agent(state_dim=state_dim, action_dim=action_dim)\n",
    "\n",
    "    if os.path.exists(RL_MODEL_PATH):\n",
    "        print(\"üîÑ Âä†ËΩΩÁé∞Êúâ RL Ê®°ÂûãÔºåËøõË°åÊñ≠ÁÇπÁª≠ËÆ≠...\")\n",
    "        rl_agent.load_model(RL_MODEL_PATH)\n",
    "\n",
    "    rl_agent.train(batch_size=64)\n",
    "    rl_agent.save_model(RL_MODEL_PATH)\n",
    "    print(f\"‚úÖ RL Ê®°ÂûãÂ∑≤‰øùÂ≠òËá≥: {RL_MODEL_PATH}\")\n",
    "\n",
    "# =============================\n",
    "# 5. Ê®°ÂûãËØÑ‰º∞\n",
    "# =============================\n",
    "def evaluate_models(feature_data):\n",
    "    print(\"üìä Ê≠£Âú®ËØÑ‰º∞Ê®°ÂûãË°®Áé∞...\")\n",
    "\n",
    "    lightgbm_model = load_lightgbm(LGB_MODEL_PATH)\n",
    "    lstm_model = load_lstm(LSTM_MODEL_PATH, input_dim=4)\n",
    "\n",
    "    metrics = evaluate_strategy(feature_data)\n",
    "    print(\"‚úÖ Ê®°ÂûãËØÑ‰º∞ÁªìÊûú:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "    # ============ ‰ª•‰∏ã‰∏∫Êñ∞Â¢ûÁöÑÊåáÊ†á‰øùÂ≠ò‰∏éÂèØËßÜÂåñÈÉ®ÂàÜ ============\n",
    "\n",
    "    # 1) Êää 14 ‰∏™ÊåáÊ†áÂÜôÂÖ•ÊåáÂÆötxtÊñá‰ª∂\n",
    "    metric_order = [\n",
    "        \"Annualized Return\",\n",
    "        \"Sharpe Ratio\",\n",
    "        \"Max Drawdown\",\n",
    "        \"Volatility\",\n",
    "        \"Downside Volatility\",\n",
    "        \"Sortino Ratio\",\n",
    "        \"Information Ratio\",\n",
    "        \"Win Rate\",\n",
    "        \"Profit/Loss Ratio\",\n",
    "        \"Trading Frequency\",\n",
    "        \"Alpha\",\n",
    "        \"Beta\",\n",
    "        \"Calmar Ratio\",\n",
    "        \"Strategy Consistency\"\n",
    "    ]\n",
    "    # ÂÜôÂÖ• EVAL_METRICS_PATH\n",
    "    with open(EVAL_METRICS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"‰ª•‰∏ã‰∏∫ 14 È°πÂÖ≥ÈîÆËØÑ‰ª∑ÊåáÊ†áÔºö\\n\\n\")\n",
    "        for m in metric_order:\n",
    "            val = metrics.get(m, 0.0)\n",
    "            f.write(f\"{m}: {val}\\n\")\n",
    "\n",
    "    # 2) ÁªòÂà∂ÊùÉÁõäÊõ≤Á∫øÂπ∂‰øùÂ≠ò‰∏∫ÂõæÁâá\n",
    "    if \"equity_curve\" in metrics:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        metrics[\"equity_curve\"].plot()\n",
    "        plt.title(\"Equity Curve\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Portfolio Value\")\n",
    "        plt.grid(True)\n",
    "        plt.savefig(EQUITY_CURVE_PATH, dpi=150, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(f\"‚úÖ Â∑≤‰øùÂ≠òÊùÉÁõäÊõ≤Á∫øÂõæÂà∞: {EQUITY_CURVE_PATH}\")\n",
    "\n",
    "# =============================\n",
    "# 6. ËÆ≠ÁªÉÊµÅÁ®ãÊï¥Âêà\n",
    "# =============================\n",
    "def train_pipeline():\n",
    "    # Step 1: Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ\n",
    "    feature_data = preprocess_data()\n",
    "\n",
    "    # Step 2: ËÆ≠ÁªÉ‰ø°Âè∑Ê®°Âûã\n",
    "    train_signal_models(feature_data)\n",
    "\n",
    "    # Step 3: ËøêË°åÂ∏ÇÂú∫ÂõûÊîæ\n",
    "    run_market_replay(feature_data)\n",
    "\n",
    "    # Step 4: ËÆ≠ÁªÉ RL Ê®°Âûã\n",
    "    train_rl_model(feature_data)\n",
    "\n",
    "    # Step 5: Ê®°ÂûãËØÑ‰º∞\n",
    "    evaluate_models(feature_data)\n",
    "\n",
    "    print(\"‚úÖ ÂÆåÊï¥ËÆ≠ÁªÉÊµÅÁ®ãÂÆåÊàêÔºÅ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823df221-696c-4930-ad3a-9f8c0a134eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ IMM Á≠ñÁï•Â§çÁé∞È°πÁõÆÂêØÂä®...\n",
      "‚úÖ Â∑≤ÂèëÁé∞Â∑≤Â§ÑÁêÜÊï∞ÊçÆÊñá‰ª∂: ./data/processed/processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "from src.data_preprocessing import load_data, process_data, generate_features\n",
    "from src.signal_model import train_lightgbm, train_lstm\n",
    "from src.market_replay import MarketReplaySimulator\n",
    "from src.rl_model import TD3_Agent\n",
    "from src.evaluation import evaluate_strategy\n",
    "from src.train import train_pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# =============================\n",
    "# ÈÖçÁΩÆË∑ØÂæÑ\n",
    "# =============================\n",
    "RAW_DATA_PATH = \"/nas197/uhome/zhangrui/merged_transaction_20241113.csv\"\n",
    "PROCESSED_DATA_PATH = \"./data/processed/processed_data.csv\"\n",
    "FEATURES_PATH = \"./data/features/executed_orders.csv\"\n",
    "LGB_MODEL_PATH = \"./models/signal_model.pkl\"\n",
    "LSTM_MODEL_PATH = \"./models/lstm_model.pth\"\n",
    "RL_MODEL_PATH = \"./models/rl_model.pth\"\n",
    "\n",
    "# === Êñ∞Â¢ûÔºöËØÑ‰ª∑ÊåáÊ†á‰∏éÂèØËßÜÂåñÊñá‰ª∂ÁöÑ‰øùÂ≠òË∑ØÂæÑ ===\n",
    "EVAL_METRICS_PATH = \"./results/evaluation_metrics.txt\"\n",
    "EQUITY_CURVE_PATH = \"./results/equity_curve.png\"\n",
    "\n",
    "# =============================\n",
    "# Êó•ÂøóÊñá‰ª∂ÈÖçÁΩÆ\n",
    "# =============================\n",
    "RESULT_LOG_PATH = \"./results/result_001.txt\"\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, log_path):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(log_path, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "\n",
    "# ÂêØÂä®Êó•ÂøóÁ≥ªÁªü\n",
    "sys.stdout = Logger(RESULT_LOG_PATH)\n",
    "\n",
    "# =============================\n",
    "# 1. ‰∏ªÊµÅÁ®ãÂÖ•Âè£\n",
    "# =============================\n",
    "def main():\n",
    "    print(\"üöÄ IMM Á≠ñÁï•Â§çÁé∞È°πÁõÆÂêØÂä®...\")\n",
    "\n",
    "    # Step 1: Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ\n",
    "    if not os.path.exists(PROCESSED_DATA_PATH):\n",
    "        print(\"üîÑ [1/5] Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ‰∏≠...\")\n",
    "        data = load_data(RAW_DATA_PATH)\n",
    "        processed_data = process_data(data)\n",
    "        feature_data = generate_features(processed_data)\n",
    "        feature_data.to_csv(PROCESSED_DATA_PATH, index=False)\n",
    "        print(f\"‚úÖ Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÂÆåÊàêÔºåÂ∑≤‰øùÂ≠òËá≥: {PROCESSED_DATA_PATH}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Â∑≤ÂèëÁé∞Â∑≤Â§ÑÁêÜÊï∞ÊçÆÊñá‰ª∂: {PROCESSED_DATA_PATH}\")\n",
    "        feature_data = pd.read_csv(PROCESSED_DATA_PATH)\n",
    "\n",
    "    # Step 2: ËÆ≠ÁªÉ‰ø°Âè∑Ê®°Âûã\n",
    "    print(\"üöÄ [2/5] ËÆ≠ÁªÉ‰ø°Âè∑Ê®°Âûã...\")\n",
    "    train_lightgbm(feature_data, LGB_MODEL_PATH)\n",
    "    train_lstm(feature_data, LSTM_MODEL_PATH)\n",
    "\n",
    "    # Step 3: Â∏ÇÂú∫ÂõûÊîæ\n",
    "    print(\"üöÄ [3/5] ÂêØÂä®Â∏ÇÂú∫ÂõûÊîæÊ®°ÊãüÂô®...\")\n",
    "    if not os.path.exists(FEATURES_PATH):\n",
    "        simulator = MarketReplaySimulator(feature_data)\n",
    "        simulator.market_replay()\n",
    "        simulator.save_executed_orders(FEATURES_PATH)\n",
    "        print(f\"‚úÖ Â∏ÇÂú∫ÂõûÊîæÂÆåÊàêÔºåÂ∑≤‰øùÂ≠òËá≥: {FEATURES_PATH}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Â∏ÇÂú∫ÂõûÊîæÊï∞ÊçÆÂ∑≤Â≠òÂú®ÔºåË∑≥ËøáÂõûÊîæ„ÄÇ\")\n",
    "\n",
    "    # Step 4: Âº∫ÂåñÂ≠¶‰π†Ê®°ÂûãËÆ≠ÁªÉ\n",
    "    print(\"üöÄ [4/5] ËÆ≠ÁªÉÂº∫ÂåñÂ≠¶‰π†Ê®°Âûã...\")\n",
    "    simulator = MarketReplaySimulator(feature_data)\n",
    "    rl_agent = TD3_Agent(state_dim=simulator.state_dim, action_dim=simulator.action_dim)\n",
    "\n",
    "    if os.path.exists(RL_MODEL_PATH):\n",
    "        print(\"üîÑ Âä†ËΩΩÁé∞Êúâ RL Ê®°ÂûãÔºåËøõË°åÊñ≠ÁÇπÁª≠ËÆ≠...\")\n",
    "        rl_agent.load_model(RL_MODEL_PATH)\n",
    "\n",
    "    rl_agent.train(batch_size=64)\n",
    "    rl_agent.save_model(RL_MODEL_PATH)\n",
    "    print(f\"‚úÖ RL Ê®°ÂûãÂ∑≤‰øùÂ≠òËá≥: {RL_MODEL_PATH}\")\n",
    "\n",
    "    # Step 5: ËØÑ‰º∞Ê®°Âûã\n",
    "    print(\"üìä [5/5] Ê≠£Âú®ËØÑ‰º∞Ê®°ÂûãË°®Áé∞...\")\n",
    "    metrics = evaluate_strategy(feature_data)\n",
    "    print(\"‚úÖ Ê®°ÂûãËØÑ‰º∞ÁªìÊûú:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "    print(\"‚úÖ IMM Á≠ñÁï•Â§çÁé∞È°πÁõÆÂÆåÊàêÔºÅ\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ce1de0-327b-4f2c-976b-566f6cf862e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ea7a0-37b2-4dd4-bca5-a328ae7902f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
